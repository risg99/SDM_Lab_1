{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72254903",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='partner.semanticscholar.org', port=443): Read timed out. (read timeout=10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mtimeout\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mtimeout\u001b[0m: The read operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:785\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    783\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 785\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/urllib3/util/retry.py:550\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 550\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/urllib3/packages/six.py:770\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 770\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:451\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:340\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m timeout_value\n\u001b[1;32m    342\u001b[0m     )\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3. In Python 2 we have\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# to specifically catch it and throw the timeout error\u001b[39;00m\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='partner.semanticscholar.org', port=443): Read timed out. (read timeout=10)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m s2_api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1WBrQVQGeo6ZZI2eJmWMk2eFnmgl8W1T7VEDvRyQ\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m sch \u001b[38;5;241m=\u001b[39m SemanticScholar(api_key\u001b[38;5;241m=\u001b[39ms2_api_key)\n\u001b[0;32m----> 6\u001b[0m ds_papers \u001b[38;5;241m=\u001b[39m \u001b[43msch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_paper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata science\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m se_papers \u001b[38;5;241m=\u001b[39m sch\u001b[38;5;241m.\u001b[39msearch_paper(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftware engineering\u001b[39m\u001b[38;5;124m'\u001b[39m, limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      8\u001b[0m bi_papers \u001b[38;5;241m=\u001b[39m sch\u001b[38;5;241m.\u001b[39msearch_paper(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbioinformatics\u001b[39m\u001b[38;5;124m'\u001b[39m, limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/semanticscholar/SemanticScholar.py:334\u001b[0m, in \u001b[0;36mSemanticScholar.search_paper\u001b[0;34m(self, query, year, fields_of_study, fields, limit)\u001b[0m\n\u001b[1;32m    331\u001b[0m     fields_of_study \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(fields_of_study)\n\u001b[1;32m    332\u001b[0m     query \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m&fields_of_study=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfields_of_study\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 334\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mPaginatedResults\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requester\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mPaper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth_header\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/semanticscholar/PaginatedResults.py:38\u001b[0m, in \u001b[0;36mPaginatedResults.__init__\u001b[0;34m(self, requester, data_type, url, query, fields, limit, headers)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_next_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/semanticscholar/PaginatedResults.py:95\u001b[0m, in \u001b[0;36mPaginatedResults.__get_next_page\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_next_page\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__build_params()\n\u001b[0;32m---> 95\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_requester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_headers\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m results \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[38;5;241m=\u001b[39m fut\u001b[38;5;241m.\u001b[39mfailed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fut\u001b[38;5;241m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/semanticscholar/ApiRequester.py:63\u001b[0m, in \u001b[0;36mApiRequester.get_data\u001b[0;34m(self, url, parameters, headers, payload)\u001b[0m\n\u001b[1;32m     61\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m payload \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     62\u001b[0m payload \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(payload) \u001b[38;5;28;01mif\u001b[39;00m payload \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m data \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/requests/adapters.py:578\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[0;32m--> 578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='partner.semanticscholar.org', port=443): Read timed out. (read timeout=10)"
     ]
    }
   ],
   "source": [
    "### Semantic scholar data\n",
    "from semanticscholar import SemanticScholar\n",
    "s2_api_key = '1WBrQVQGeo6ZZI2eJmWMk2eFnmgl8W1T7VEDvRyQ'\n",
    "sch = SemanticScholar(api_key=s2_api_key)\n",
    "\n",
    "ds_papers = sch.search_paper('data science', limit=100)\n",
    "se_papers = sch.search_paper('software engineering', limit=100)\n",
    "bi_papers = sch.search_paper('bioinformatics', limit=100)\n",
    "graph_papers = sch.search_paper('graph theory', limit=100)\n",
    "db_papers = sch.search_paper('database', limit=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fdb3ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dump dataset\n",
    "import json\n",
    "\n",
    "dataset = [ds_papers, se_papers, bi_papers, graph_papers, db_papers]\n",
    "\n",
    "result = []\n",
    "for data in dataset:\n",
    "    \n",
    "    length = 1\n",
    "    for res in data:\n",
    "        if length > 500:\n",
    "            break\n",
    "            \n",
    "        length += 1\n",
    "        result.append(res)\n",
    "\n",
    "# with open('dataset.json', 'w+') as f:\n",
    "#     json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd2f7e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m fake\u001b[38;5;241m.\u001b[39madd_provider(address)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./uni.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 17\u001b[0m     uni \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "from faker import Faker\n",
    "from faker.providers import address, internet, sbn\n",
    "from faker_education import SchoolProvider\n",
    "from random import choice, randint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "fake = Faker()\n",
    "fake.add_provider(SchoolProvider)\n",
    "fake.add_provider(internet)\n",
    "fake.add_provider(sbn)\n",
    "fake.add_provider(address)\n",
    "\n",
    "\n",
    "with open('./uni.json', 'r') as f:\n",
    "    uni = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8dcbea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parse the authors\n",
    "authors = {\":ID\": [], \"name:STRING\": [], \"email:STRING\": [], \"department:STRING\": [], \"institution:STRING\":[]}\n",
    "author_ids = set()\n",
    "\n",
    "author_writes_papers = {\":START_ID\" : [], \":END_ID\": [], \"corresponding_author:BOOLEAN\": []}\n",
    "author_papers = {}\n",
    "\n",
    "for res in result:\n",
    "    ### Assume first author is corresponding author\n",
    "    corresponding_author = True\n",
    "    for author in res.authors:\n",
    "        author_writes_papers[\":START_ID\"].append(author.authorId)\n",
    "        author_writes_papers[\":END_ID\"].append(res.paperId)\n",
    "        author_writes_papers[\"corresponding_author:BOOLEAN\"].append(corresponding_author)\n",
    "        \n",
    "        corresponding_author = False\n",
    "        \n",
    "        ### Add author papers relation\n",
    "        p = author_papers.setdefault(author.authorId, set())\n",
    "        p.add(res.paperId)\n",
    "        author_papers[author.authorId] = p\n",
    "        \n",
    "        if author.authorId in author_ids:\n",
    "            continue\n",
    "            \n",
    "        gender = np.random.choice([\"M\", \"F\"], p=[0.5, 0.5])\n",
    "        first_name = fake.first_name_male() if gender ==\"M\" else fake.first_name_female()\n",
    "        last_name = fake.last_name()\n",
    "        \n",
    "        author_ids.add(author.authorId)\n",
    "        \n",
    "        authors[\":ID\"].append(author.authorId)\n",
    "        authors[\"name:STRING\"].append(author.name)\n",
    "        authors[\"email:STRING\"].append(f'{first_name}.{last_name}@{fake.domain_name()}')\n",
    "        authors[\"department:STRING\"].append(fake.school_type())\n",
    "        authors[\"institution:STRING\"].append(uni[randint(0, len(uni)-1)]['institution'])\n",
    "\n",
    "authors_df = pd.DataFrame.from_dict(authors)\n",
    "authors_df.to_csv('authors_node_semantic.csv')\n",
    "\n",
    "author_wp_df =  pd.DataFrame.from_dict(author_writes_papers)\n",
    "author_wp_df.to_csv('author_writes_papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b9992a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parse the paper & keywords\n",
    "papers = {\":ID\": [], \"title:STRING\": [], \"abstract:STRING\": [], \"pages:STRING\": [], \"DOI:STRING\":[], \"link:STRING\":[]}\n",
    "paper_has_keywords = {\":START_ID\" : [], \":END_ID\": []}\n",
    "papers_set = set()\n",
    "\n",
    "keywords = {\":ID\": [], \"name:STRING\": [], \"domain:STRING\": []}\n",
    "keywords_dict = {}\n",
    "\n",
    "for res in result:\n",
    "    papers_set.add(res.paperId)\n",
    "    papers[\":ID\"].append(res.paperId)\n",
    "    papers[\"title:STRING\"].append(res.title)\n",
    "    papers[\"abstract:STRING\"].append(res.abstract)\n",
    "    \n",
    "    pages = f'{randint(15,100)}-{randint(101,150)}'\n",
    "    if res.journal is not None:\n",
    "        pages = res.journal.pages if res.journal.pages is not None else pages\n",
    "    papers[\"pages:STRING\"].append(pages)\n",
    "    \n",
    "    papers[\"DOI:STRING\"].append(res.externalIds.get('DOI', fake.sbn9()))\n",
    "    papers[\"link:STRING\"].append(fake.uri())\n",
    "    \n",
    "    if res.fieldsOfStudy is None or len(res.fieldsOfStudy) == 0:\n",
    "        paper_has_keywords[\":START_ID\"].append(res.paperId)\n",
    "        paper_has_keywords[\":END_ID\"].append(choice(list(keywords_dict.values())))\n",
    "    else:\n",
    "        for fs in res.fieldsOfStudy:\n",
    "            fs_id = str(uuid.uuid4())\n",
    "            if fs not in keywords_dict:\n",
    "                keywords[\":ID\"].append(fs_id)\n",
    "                keywords[\"name:STRING\"].append(fs)\n",
    "                keywords[\"domain:STRING\"].append(res.fieldsOfStudy[0])\n",
    "\n",
    "            k_id = keywords_dict.setdefault(fs, fs_id)\n",
    "\n",
    "            paper_has_keywords[\":START_ID\"].append(res.paperId)\n",
    "            paper_has_keywords[\":END_ID\"].append(k_id)\n",
    "    \n",
    "papers_df = pd.DataFrame.from_dict(papers)\n",
    "papers_df.to_csv('papers_semantic.csv')\n",
    "\n",
    "keywords_df = pd.DataFrame.from_dict(keywords)\n",
    "keywords_df.to_csv('keywords_semantic.csv')\n",
    "\n",
    "paper_has_kw = pd.DataFrame.from_dict(paper_has_keywords)\n",
    "paper_has_kw.to_csv('paper_has_keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6087c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create reviewers relationships\\\n",
    "author_review_papers = {\":START_ID\" : [], \":END_ID\": []}\n",
    "\n",
    "for paper in list(papers_set):\n",
    "    # Pick 3 reviewers per paper\n",
    "    for i in range(3):\n",
    "        reviewed = False\n",
    "        while not reviewed:\n",
    "            \n",
    "            # Make sure author not reviewing the same paper\n",
    "            author = choice(list(author_papers.keys()))\n",
    "            if paper in author_papers[author]:\n",
    "                continue\n",
    "            \n",
    "            author_review_papers[\":START_ID\"].append(author)\n",
    "            author_review_papers[\":END_ID\"].append(paper)\n",
    "            reviewed = True\n",
    "\n",
    "author_rp = pd.DataFrame.from_dict(author_review_papers)\n",
    "author_rp.to_csv('author_review_papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c16b00de",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create cite relationship\n",
    "### Assumption is paper is cited by [0-50] papers\n",
    "paper_cites_paper = {\":START_ID\" : [], \":END_ID\": []}\n",
    "\n",
    "for cited_paper in list(papers_set):\n",
    "    \n",
    "    for i in range(randint(0,50)):\n",
    "        cited = False\n",
    "        while not cited:\n",
    "            \n",
    "            ### Cannot cite own paper\n",
    "            paper = choice(list(papers_set))\n",
    "            if cited_paper == paper:\n",
    "                continue\n",
    "            \n",
    "            paper_cites_paper[':START_ID'].append(paper)\n",
    "            paper_cites_paper[':END_ID'].append(cited_paper)\n",
    "            cited = True\n",
    "\n",
    "pcp = pd.DataFrame.from_dict(paper_cites_paper)\n",
    "pcp.to_csv('paper_cites_paper.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "93dff842",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create journal node and relationship\n",
    "journals = {\":ID\": [], \"name:STRING\": []}\n",
    "paper_published_in_journal = {\":START_ID\" : [], \":END_ID\": [], \"volume:STRING\": [], \"year:INT\": []}\n",
    "\n",
    "default_journal = {'id': str(uuid.uuid4()), 'name': 'Unknown', 'year': 2000, 'volume': 1}\n",
    "journal_dict = {}\n",
    "\n",
    "def get_journal_data(res):\n",
    "    journal_name = default_journal['name']\n",
    "    journal_id = default_journal['id']\n",
    "    volume = default_journal['volume']\n",
    "    year = default_journal['year']\n",
    "    \n",
    "    ### Check if journal name exists in publication venue\n",
    "    if (res.publicationVenue.name and res.publicationVenue.name != ''):\n",
    "        journal_name = res.publicationVenue.name\n",
    "        journal_id =  res.publicationVenue.id\n",
    "\n",
    "    elif res.journal and res.journal.name and res.journal.name != '':\n",
    "        journal_name = res.journal.name\n",
    "        journal_id = str(uuid.uuid4())\n",
    "    \n",
    "    ### No data about the journal\n",
    "    else:\n",
    "        return journal_name, journal_id, volume, year\n",
    "    \n",
    "    ### If volume and year not found but there is journal name\n",
    "    if (res.publicationVenue and res.publicationVenue.type == 'journal' and res.year and res.year != ''):\n",
    "        year = res.year\n",
    "    if res.journal and res.journal.volume and res.journal.volume != '':\n",
    "        volume = res.journal.volume\n",
    "\n",
    "    return journal_name, journal_id, volume, year\n",
    "\n",
    "for res in result:\n",
    "    if not (res.publicationVenue and res.publicationVenue.type == 'journal'):\n",
    "        continue\n",
    "        \n",
    "    journal_name, journal_id, volume, year = get_journal_data(res)\n",
    "    \n",
    "    paper_published_in_journal[':START_ID'].append(res.paperId)\n",
    "    paper_published_in_journal[':END_ID'].append(journal_id)\n",
    "    paper_published_in_journal['volume:STRING'].append(volume)\n",
    "    paper_published_in_journal['year:INT'].append(int(year))\n",
    "    \n",
    "    \n",
    "    if journal_name in journal_dict:\n",
    "        continue\n",
    "    \n",
    "    journal_dict.setdefault(journal_name, journal_id)\n",
    "    journals[':ID'].append(journal_id)\n",
    "    journals['name:STRING'].append(journal_name)\n",
    "\n",
    "jdf = pd.DataFrame.from_dict(journals)\n",
    "jdf.to_csv('journal_semantic.csv')\n",
    "\n",
    "ppij = pd.DataFrame.from_dict(paper_published_in_journal)\n",
    "ppij.to_csv('paper_published_in_journal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "41f0cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create conference proceedings node and relationship\n",
    "conference = {\":ID\": [], \"name:STRING\": [], 'year:INT': []}\n",
    "proceedings = {\":ID\": [], \"name:STRING\": [], 'city:STRING': []}\n",
    "\n",
    "paper_presented_in_conference = {\":START_ID\" : [], \":END_ID\": []}\n",
    "conference_part_of_proceedings = {\":START_ID\" : [], \":END_ID\": []}\n",
    "\n",
    "default_conference_proceeding = {'name': 'Unknown', 'year': 2000, 'city': 'Boston', 'proc_id': str(uuid.uuid4())}\n",
    "conference_dict = {}\n",
    "\n",
    "def get_conference_data(res):\n",
    "    conference_name = default_conference_proceeding['name']\n",
    "    conference_id = str(uuid.uuid4())\n",
    "    conference_year = default_conference_proceeding['year']\n",
    "    \n",
    "    if (res.publicationVenue.name and res.publicationVenue.name != ''):\n",
    "        conference_name = res.publicationVenue.name\n",
    "    \n",
    "    if (res.publicationVenue.id and res.publicationVenue.id != ''):\n",
    "        conference_id = res.publicationVenue.id\n",
    "    \n",
    "    if (res.year and res.year != ''):\n",
    "        conference_year = res.year\n",
    "    \n",
    "    return conference_name, conference_id, conference_year\n",
    "\n",
    "def get_proceeding_data(res):\n",
    "    proc_name = default_conference_proceeding['name']\n",
    "    proc_id = str(uuid.uuid4())\n",
    "    \n",
    "    if res.journal and res.journal.name and res.journal.name != '':\n",
    "        proc_name = res.journal.name\n",
    "    \n",
    "    return proc_name, proc_id, fake.city()\n",
    "\n",
    "for res in result:\n",
    "    if not (res.publicationVenue and res.publicationVenue.type == 'conference'):\n",
    "        continue\n",
    "    \n",
    "    conference_name, conference_id, conference_year = get_conference_data(res)\n",
    "    if conference_id not in conference_dict:\n",
    "        data = conference_dict.setdefault(conference_id, {})\n",
    "        data['proceeding'] = {}\n",
    "        proc_name, proc_id, city = get_proceeding_data(res)\n",
    "        \n",
    "        data['proceeding']['name'] = proc_name\n",
    "        data['proceeding']['id'] = proc_id\n",
    "        data['proceeding']['city'] = city\n",
    "        \n",
    "        data['conference'] = {}\n",
    "        data['conference']['name'] = conference_name\n",
    "        data['conference']['id'] = conference_id\n",
    "        data['conference']['year'] = conference_year\n",
    "        \n",
    "        conference_dict[conference_id] = data\n",
    "    \n",
    "        conference[':ID'].append(conference_id)\n",
    "        conference['name:STRING'].append(conference_name)\n",
    "        conference['year:INT'].append(int(conference_year))\n",
    "        \n",
    "        proceedings[':ID'].append(proc_id)\n",
    "        proceedings['name:STRING'].append(proc_name)\n",
    "        proceedings['city:STRING'].append(city)\n",
    "        \n",
    "        conference_part_of_proceedings[':START_ID'].append(conference_id)\n",
    "        conference_part_of_proceedings[':END_ID'].append(proc_id)\n",
    "    \n",
    "    \n",
    "    paper_presented_in_conference[':START_ID'].append(res.paperId)\n",
    "    paper_presented_in_conference[':END_ID'].append(conference_id)\n",
    "    \n",
    "\n",
    "cf = pd.DataFrame.from_dict(conference)\n",
    "cf.to_csv('conference_semantic.csv')\n",
    "\n",
    "pcdgs = pd.DataFrame.from_dict(proceedings)\n",
    "pcdgs.to_csv('proceedings_semantic.csv')\n",
    "\n",
    "ppic = pd.DataFrame.from_dict(paper_presented_in_conference)\n",
    "ppic.to_csv('paper_presented_in_conference.csv')\n",
    "\n",
    "cpop = pd.DataFrame.from_dict(conference_part_of_proceedings)\n",
    "cpop.to_csv('conference_part_of_proceedings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7760a15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_425527/3443303136.py:8: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  published_papers = set(ppij[\":START_ID\"].append(ppij[\":START_ID\"], ignore_index=True))\n"
     ]
    }
   ],
   "source": [
    "### Transform coference with editions\n",
    "cdf = pd.read_csv('conference_semantic.csv', index_col=False)\n",
    "ppij = pd.read_csv('paper_published_in_journal.csv', index_col=False)\n",
    "ppic = pd.read_csv('paper_presented_in_conference.csv', index_col=False)\n",
    "papers = pd.read_csv('papers_semantic.csv', index_col=False)\n",
    "awp = pd.read_csv('author_writes_papers.csv')\n",
    " \n",
    "published_papers = set(ppij[\":START_ID\"].append(ppij[\":START_ID\"], ignore_index=True))\n",
    "paper_set = set(papers[\":ID\"])\n",
    "\n",
    "unpublished_papers = paper_set.difference(published_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a579df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add conference Data\n",
    "conference_ids = [\"7654260e-79f9-45c5-9663-d72027cf88f3\",\n",
    "\"376732f4-ec63-4b76-bfc8-bbf77119d852\",\n",
    "\"25eaf793-6674-4a6d-864f-6c8ae5428912\",\n",
    "\"1123f25d-add0-4c9c-8f43-c877aab90a0b\",\n",
    "\"b1ee6f13-7776-44aa-a2d5-b79deda2aecb\",\n",
    "\"b83b14d5-4e97-4f22-85e2-0b30dfa042f4\",\n",
    "\"c40f4908-60d1-42b4-8890-380119178833\",\n",
    "\"5afb995f-87ba-455e-bd26-86ae67a10447\",\n",
    "\"c2ff5df6-f2f4-4573-a884-8c53979d4c78\",\n",
    "\"5042fe05-b1f6-41b6-8092-53294b52cbd6\",\n",
    "\"bb718fdd-6d66-4f93-851b-08eeeefb28f5\",\n",
    "\"0efa120a-36c7-45fa-b534-597651ae69d2\",\n",
    "\"019d3f59-a115-42e3-bd7b-474dd4246499\",\n",
    "\"bedd754b-5faf-4eff-8074-3c90be8ac9b0\",\n",
    "\"0256ebd3-4f16-4fd0-91bc-b0e77fcd3c0d\",\n",
    "\"f3dd946e-cb75-4502-b550-9dec04bda7f9\",\n",
    "\"3ff00d27-28c7-4770-a1c7-855a072843fd\",\n",
    "\"4c562775-121a-4c25-9f7a-823f54d0e93e\",\n",
    "\"10ff739d-ef5f-48b7-9454-9cd1c6d2434d\",\n",
    "\"3837ff2b-82e5-4165-8900-b069c31ef3d7\",\n",
    "\"b55b50b1-aae7-47a7-b042-8aecc930073d\",\n",
    "\"c85dfc25-bcef-4719-9997-f41ad334d998\",\n",
    "\"d7907408-25bc-4816-a81d-4e0f2f6482c8\"\n",
    "]\n",
    "\n",
    "journals = [\"c6840156-ee10-4d78-8832-7f8909811576\",\n",
    "\"d60da343-ab92-4310-b3d7-2c0860287a9d\",\n",
    "\"27475f31-a1d2-401b-84ad-9b405c7609a8\",\n",
    "\"961301b0-6f5a-44a6-9216-54b673cded78\",\n",
    "\"bc30f894-9a9c-440e-8420-7bd3c5624384\"]\n",
    "\n",
    "unpublished_papers = list(unpublished_papers)\n",
    "for_journals = unpublished_papers[len(unpublished_papers)//2+1:]\n",
    "for_conferences = unpublished_papers[:len(unpublished_papers)//2+1]\n",
    "\n",
    "\n",
    "paper_presented_in_conference = {\":START_ID\" : [], \":END_ID\": []}\n",
    "paper_published_in_journal = {\":START_ID\" : [], \":END_ID\": [], \"volume:STRING\": [], \"year:INT\": []}\n",
    "\n",
    "### Assign paper to conference\n",
    "index = 0\n",
    "for paper in for_conferences:\n",
    "    paper_presented_in_conference[\":START_ID\"].append(paper)\n",
    "    paper_presented_in_conference[\":END_ID\"].append(conference_ids[index%len(conference_ids)])\n",
    "    index += 1\n",
    "\n",
    "    \n",
    "### Assign paper to journal\n",
    "avail_paper = len(for_journals)\n",
    "while avail_paper > 0:\n",
    "    for journal in journals:\n",
    "        if avail_paper <= 0:\n",
    "            break\n",
    "\n",
    "        year = 2017\n",
    "        volume = 1\n",
    "        \n",
    "        for i in range(5):\n",
    "            if avail_paper <= 0:\n",
    "                break\n",
    "                \n",
    "            paper_published_in_journal[\":START_ID\"].append(for_journals[avail_paper-1])\n",
    "            paper_published_in_journal[\":END_ID\"].append(journal)\n",
    "            paper_published_in_journal[\"volume:STRING\"].append(volume)\n",
    "            paper_published_in_journal[\"year:INT\"].append(year)\n",
    "            \n",
    "            year += 1\n",
    "            volume += 1\n",
    "            avail_paper -= 1\n",
    "\n",
    "\n",
    "### Assign authors to review paper\n",
    "author_writes_papers = {\":START_ID\" : [], \":END_ID\": [], \"corresponding_author:BOOLEAN\": []}\n",
    "authors = [\"144110054\",\n",
    "\"147069795\",\n",
    "\"4376295\",\n",
    "\"2395456\",\n",
    "\"8504175\",\n",
    "\"145073266\"\n",
    "# \"21366050\",\n",
    "# \"1404984281\",\n",
    "# \"40281699\",\n",
    "# \"2118624194\",\n",
    "# \"21512561\",\n",
    "# \"1753164\"\n",
    "\n",
    "]\n",
    "\n",
    "avail_paper = len(for_conferences)\n",
    "while avail_paper > 0:\n",
    "    for author in authors:\n",
    "        if avail_paper <= 0:\n",
    "            break\n",
    "\n",
    "        \n",
    "        for i in range(5):\n",
    "            if avail_paper <= 0:\n",
    "                break\n",
    "                \n",
    "            author_writes_papers[\":START_ID\"].append(author)\n",
    "            author_writes_papers[\":END_ID\"].append(for_conferences[avail_paper-1])\n",
    "            author_writes_papers[\"corresponding_author:BOOLEAN\"].append(False)\n",
    "            \n",
    "            avail_paper -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a7518e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_425527/234618308.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  awp = awp.append(pd.DataFrame.from_dict(author_writes_papers), ignore_index=True)\n",
      "/tmp/ipykernel_425527/234618308.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ppij = ppij.append(pd.DataFrame.from_dict(paper_published_in_journal), ignore_index=True)\n",
      "/tmp/ipykernel_425527/234618308.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ppic = ppic.append(pd.DataFrame.from_dict(paper_presented_in_conference), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "awp = awp.append(pd.DataFrame.from_dict(author_writes_papers), ignore_index=True)\n",
    "ppij = ppij.append(pd.DataFrame.from_dict(paper_published_in_journal), ignore_index=True)\n",
    "ppic = ppic.append(pd.DataFrame.from_dict(paper_presented_in_conference), ignore_index=True)\n",
    "\n",
    "awp.drop(columns=['Unnamed: 0'])\n",
    "ppij.drop(columns=['Unnamed: 0'])\n",
    "ppic.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "awp.to_csv(\"author_write_papers_1.csv\", index=False)\n",
    "ppij.to_csv(\"paper_published_in_journal_1.csv\", index=False)\n",
    "ppic.to_csv(\"paper_presented_in_conference_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4da5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
