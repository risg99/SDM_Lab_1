{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72254903",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Semantic scholar data\n",
    "from semanticscholar import SemanticScholar\n",
    "s2_api_key = '1WBrQVQGeo6ZZI2eJmWMk2eFnmgl8W1T7VEDvRyQ'\n",
    "sch = SemanticScholar(api_key=s2_api_key)\n",
    "\n",
    "ds_papers = sch.search_paper('data science', limit=100)\n",
    "se_papers = sch.search_paper('software engineering', limit=100)\n",
    "bi_papers = sch.search_paper('bioinformatics', limit=100)\n",
    "graph_papers = sch.search_paper('graph theory', limit=100)\n",
    "db_papers = sch.search_paper('database', limit=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fdb3ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dump dataset\n",
    "import json\n",
    "\n",
    "dataset = [ds_papers, se_papers, bi_papers, graph_papers, db_papers]\n",
    "\n",
    "result = []\n",
    "for data in dataset:\n",
    "    \n",
    "    length = 1\n",
    "    for res in data:\n",
    "        if length > 500:\n",
    "            break\n",
    "            \n",
    "        length += 1\n",
    "        result.append(res)\n",
    "\n",
    "### Dump dataset as json\n",
    "with open('dataset.json', 'w+') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bd2f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "from faker.providers import address, internet, sbn\n",
    "from faker_education import SchoolProvider\n",
    "from random import choice, randint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "fake = Faker()\n",
    "fake.add_provider(SchoolProvider)\n",
    "fake.add_provider(internet)\n",
    "fake.add_provider(sbn)\n",
    "fake.add_provider(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8dcbea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parse the authors\n",
    "authors = {\":ID\": [], \"name:STRING\": [], \"email:STRING\": [], \"department:STRING\": [], \"institution:STRING\":[]}\n",
    "author_ids = set()\n",
    "\n",
    "author_writes_papers = {\":START_ID\" : [], \":END_ID\": [], \"corresponding_author:BOOLEAN\": []}\n",
    "author_papers = {}\n",
    "\n",
    "for res in result:\n",
    "    ### Assume first author is corresponding author\n",
    "    corresponding_author = True\n",
    "    for author in res.authors:\n",
    "        author_writes_papers[\":START_ID\"].append(author.authorId)\n",
    "        author_writes_papers[\":END_ID\"].append(res.paperId)\n",
    "        author_writes_papers[\"corresponding_author:BOOLEAN\"].append(corresponding_author)\n",
    "        \n",
    "        corresponding_author = False\n",
    "        \n",
    "        ### Add author papers relation\n",
    "        p = author_papers.setdefault(author.authorId, set())\n",
    "        p.add(res.paperId)\n",
    "        author_papers[author.authorId] = p\n",
    "        \n",
    "        if author.authorId in author_ids:\n",
    "            continue\n",
    "            \n",
    "        gender = np.random.choice([\"M\", \"F\"], p=[0.5, 0.5])\n",
    "        first_name = fake.first_name_male() if gender ==\"M\" else fake.first_name_female()\n",
    "        last_name = fake.last_name()\n",
    "        \n",
    "        author_ids.add(author.authorId)\n",
    "        \n",
    "        authors[\":ID\"].append(author.authorId)\n",
    "        authors[\"name:STRING\"].append(author.name)\n",
    "        authors[\"email:STRING\"].append(f'{first_name}.{last_name}@{fake.domain_name()}')\n",
    "        authors[\"department:STRING\"].append(fake.school_type())\n",
    "        authors[\"institution:STRING\"].append(uni[randint(0, len(uni)-1)]['institution'])\n",
    "\n",
    "authors_df = pd.DataFrame.from_dict(authors)\n",
    "authors_df.to_csv('authors_node_semantic.csv')\n",
    "\n",
    "author_wp_df =  pd.DataFrame.from_dict(author_writes_papers)\n",
    "author_wp_df.to_csv('author_writes_papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b9992a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parse the paper & keywords\n",
    "papers = {\":ID\": [], \"title:STRING\": [], \"abstract:STRING\": [], \"pages:STRING\": [], \"DOI:STRING\":[], \"link:STRING\":[]}\n",
    "paper_has_keywords = {\":START_ID\" : [], \":END_ID\": []}\n",
    "papers_set = set()\n",
    "\n",
    "keywords = {\":ID\": [], \"name:STRING\": [], \"domain:STRING\": []}\n",
    "keywords_dict = {}\n",
    "\n",
    "for res in result:\n",
    "    papers_set.add(res.paperId)\n",
    "    papers[\":ID\"].append(res.paperId)\n",
    "    papers[\"title:STRING\"].append(res.title)\n",
    "    papers[\"abstract:STRING\"].append(res.abstract)\n",
    "    \n",
    "    pages = f'{randint(15,100)}-{randint(101,150)}'\n",
    "    if res.journal is not None:\n",
    "        pages = res.journal.pages if res.journal.pages is not None else pages\n",
    "    papers[\"pages:STRING\"].append(pages)\n",
    "    \n",
    "    papers[\"DOI:STRING\"].append(res.externalIds.get('DOI', fake.sbn9()))\n",
    "    papers[\"link:STRING\"].append(fake.uri())\n",
    "    \n",
    "    if res.fieldsOfStudy is None or len(res.fieldsOfStudy) == 0:\n",
    "        paper_has_keywords[\":START_ID\"].append(res.paperId)\n",
    "        paper_has_keywords[\":END_ID\"].append(choice(list(keywords_dict.values())))\n",
    "    else:\n",
    "        for fs in res.fieldsOfStudy:\n",
    "            fs_id = str(uuid.uuid4())\n",
    "            if fs not in keywords_dict:\n",
    "                keywords[\":ID\"].append(fs_id)\n",
    "                keywords[\"name:STRING\"].append(fs)\n",
    "                keywords[\"domain:STRING\"].append(res.fieldsOfStudy[0])\n",
    "\n",
    "            k_id = keywords_dict.setdefault(fs, fs_id)\n",
    "\n",
    "            paper_has_keywords[\":START_ID\"].append(res.paperId)\n",
    "            paper_has_keywords[\":END_ID\"].append(k_id)\n",
    "    \n",
    "papers_df = pd.DataFrame.from_dict(papers)\n",
    "papers_df.to_csv('papers_semantic.csv')\n",
    "\n",
    "keywords_df = pd.DataFrame.from_dict(keywords)\n",
    "keywords_df.to_csv('keywords_semantic.csv')\n",
    "\n",
    "paper_has_kw = pd.DataFrame.from_dict(paper_has_keywords)\n",
    "paper_has_kw.to_csv('paper_has_keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6087c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create reviewers relationships\\\n",
    "author_review_papers = {\":START_ID\" : [], \":END_ID\": []}\n",
    "\n",
    "for paper in list(papers_set):\n",
    "    # Pick 3 reviewers per paper\n",
    "    for i in range(3):\n",
    "        reviewed = False\n",
    "        while not reviewed:\n",
    "            \n",
    "            # Make sure author not reviewing the same paper\n",
    "            author = choice(list(author_papers.keys()))\n",
    "            if paper in author_papers[author]:\n",
    "                continue\n",
    "            \n",
    "            author_review_papers[\":START_ID\"].append(author)\n",
    "            author_review_papers[\":END_ID\"].append(paper)\n",
    "            reviewed = True\n",
    "\n",
    "author_rp = pd.DataFrame.from_dict(author_review_papers)\n",
    "author_rp.to_csv('author_review_papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c16b00de",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create cite relationship\n",
    "### Assumption is paper is cited by [0-50] papers\n",
    "paper_cites_paper = {\":START_ID\" : [], \":END_ID\": []}\n",
    "\n",
    "for cited_paper in list(papers_set):\n",
    "    \n",
    "    for i in range(randint(0,50)):\n",
    "        cited = False\n",
    "        while not cited:\n",
    "            \n",
    "            ### Cannot cite own paper\n",
    "            paper = choice(list(papers_set))\n",
    "            if cited_paper == paper:\n",
    "                continue\n",
    "            \n",
    "            paper_cites_paper[':START_ID'].append(paper)\n",
    "            paper_cites_paper[':END_ID'].append(cited_paper)\n",
    "            cited = True\n",
    "\n",
    "pcp = pd.DataFrame.from_dict(paper_cites_paper)\n",
    "pcp.to_csv('paper_cites_paper.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "93dff842",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create journal node and relationship\n",
    "journals = {\":ID\": [], \"name:STRING\": []}\n",
    "paper_published_in_journal = {\":START_ID\" : [], \":END_ID\": [], \"volume:STRING\": [], \"year:INT\": []}\n",
    "\n",
    "default_journal = {'id': str(uuid.uuid4()), 'name': 'Unknown', 'year': 2000, 'volume': 1}\n",
    "journal_dict = {}\n",
    "\n",
    "def get_journal_data(res):\n",
    "    journal_name = default_journal['name']\n",
    "    journal_id = default_journal['id']\n",
    "    volume = default_journal['volume']\n",
    "    year = default_journal['year']\n",
    "    \n",
    "    ### Check if journal name exists in publication venue\n",
    "    if (res.publicationVenue.name and res.publicationVenue.name != ''):\n",
    "        journal_name = res.publicationVenue.name\n",
    "        journal_id =  res.publicationVenue.id\n",
    "\n",
    "    elif res.journal and res.journal.name and res.journal.name != '':\n",
    "        journal_name = res.journal.name\n",
    "        journal_id = str(uuid.uuid4())\n",
    "    \n",
    "    ### No data about the journal\n",
    "    else:\n",
    "        return journal_name, journal_id, volume, year\n",
    "    \n",
    "    ### If volume and year not found but there is journal name\n",
    "    if (res.publicationVenue and res.publicationVenue.type == 'journal' and res.year and res.year != ''):\n",
    "        year = res.year\n",
    "    if res.journal and res.journal.volume and res.journal.volume != '':\n",
    "        volume = res.journal.volume\n",
    "\n",
    "    return journal_name, journal_id, volume, year\n",
    "\n",
    "for res in result:\n",
    "    if not (res.publicationVenue and res.publicationVenue.type == 'journal'):\n",
    "        continue\n",
    "        \n",
    "    journal_name, journal_id, volume, year = get_journal_data(res)\n",
    "    \n",
    "    paper_published_in_journal[':START_ID'].append(res.paperId)\n",
    "    paper_published_in_journal[':END_ID'].append(journal_id)\n",
    "    paper_published_in_journal['volume:STRING'].append(volume)\n",
    "    paper_published_in_journal['year:INT'].append(int(year))\n",
    "    \n",
    "    \n",
    "    if journal_name in journal_dict:\n",
    "        continue\n",
    "    \n",
    "    journal_dict.setdefault(journal_name, journal_id)\n",
    "    journals[':ID'].append(journal_id)\n",
    "    journals['name:STRING'].append(journal_name)\n",
    "\n",
    "jdf = pd.DataFrame.from_dict(journals)\n",
    "jdf.to_csv('journal_semantic.csv')\n",
    "\n",
    "ppij = pd.DataFrame.from_dict(paper_published_in_journal)\n",
    "ppij.to_csv('paper_published_in_journal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "41f0cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create conference proceedings node and relationship\n",
    "conference = {\":ID\": [], \"name:STRING\": [], 'year:INT': []}\n",
    "proceedings = {\":ID\": [], \"name:STRING\": [], 'city:STRING': []}\n",
    "\n",
    "paper_presented_in_conference = {\":START_ID\" : [], \":END_ID\": []}\n",
    "conference_part_of_proceedings = {\":START_ID\" : [], \":END_ID\": []}\n",
    "\n",
    "default_conference_proceeding = {'name': 'Unknown', 'year': 2000, 'city': 'Boston', 'proc_id': str(uuid.uuid4())}\n",
    "conference_dict = {}\n",
    "\n",
    "def get_conference_data(res):\n",
    "    conference_name = default_conference_proceeding['name']\n",
    "    conference_id = str(uuid.uuid4())\n",
    "    conference_year = default_conference_proceeding['year']\n",
    "    \n",
    "    if (res.publicationVenue.name and res.publicationVenue.name != ''):\n",
    "        conference_name = res.publicationVenue.name\n",
    "    \n",
    "    if (res.publicationVenue.id and res.publicationVenue.id != ''):\n",
    "        conference_id = res.publicationVenue.id\n",
    "    \n",
    "    if (res.year and res.year != ''):\n",
    "        conference_year = res.year\n",
    "    \n",
    "    return conference_name, conference_id, conference_year\n",
    "\n",
    "def get_proceeding_data(res):\n",
    "    proc_name = default_conference_proceeding['name']\n",
    "    proc_id = str(uuid.uuid4())\n",
    "    \n",
    "    if res.journal and res.journal.name and res.journal.name != '':\n",
    "        proc_name = res.journal.name\n",
    "    \n",
    "    return proc_name, proc_id, fake.city()\n",
    "\n",
    "for res in result:\n",
    "    if not (res.publicationVenue and res.publicationVenue.type == 'conference'):\n",
    "        continue\n",
    "    \n",
    "    conference_name, conference_id, conference_year = get_conference_data(res)\n",
    "    if conference_id not in conference_dict:\n",
    "        data = conference_dict.setdefault(conference_id, {})\n",
    "        data['proceeding'] = {}\n",
    "        proc_name, proc_id, city = get_proceeding_data(res)\n",
    "        \n",
    "        data['proceeding']['name'] = proc_name\n",
    "        data['proceeding']['id'] = proc_id\n",
    "        data['proceeding']['city'] = city\n",
    "        \n",
    "        data['conference'] = {}\n",
    "        data['conference']['name'] = conference_name\n",
    "        data['conference']['id'] = conference_id\n",
    "        data['conference']['year'] = conference_year\n",
    "        \n",
    "        conference_dict[conference_id] = data\n",
    "    \n",
    "        conference[':ID'].append(conference_id)\n",
    "        conference['name:STRING'].append(conference_name)\n",
    "        conference['year:INT'].append(int(conference_year))\n",
    "        \n",
    "        proceedings[':ID'].append(proc_id)\n",
    "        proceedings['name:STRING'].append(proc_name)\n",
    "        proceedings['city:STRING'].append(city)\n",
    "        \n",
    "        conference_part_of_proceedings[':START_ID'].append(conference_id)\n",
    "        conference_part_of_proceedings[':END_ID'].append(proc_id)\n",
    "    \n",
    "    \n",
    "    paper_presented_in_conference[':START_ID'].append(res.paperId)\n",
    "    paper_presented_in_conference[':END_ID'].append(conference_id)\n",
    "    \n",
    "\n",
    "cf = pd.DataFrame.from_dict(conference)\n",
    "cf.to_csv('conference_semantic.csv')\n",
    "\n",
    "pcdgs = pd.DataFrame.from_dict(proceedings)\n",
    "pcdgs.to_csv('proceedings_semantic.csv')\n",
    "\n",
    "ppic = pd.DataFrame.from_dict(paper_presented_in_conference)\n",
    "ppic.to_csv('paper_presented_in_conference.csv')\n",
    "\n",
    "cpop = pd.DataFrame.from_dict(conference_part_of_proceedings)\n",
    "cpop.to_csv('conference_part_of_proceedings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7760a15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_425527/3443303136.py:8: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  published_papers = set(ppij[\":START_ID\"].append(ppij[\":START_ID\"], ignore_index=True))\n"
     ]
    }
   ],
   "source": [
    "### Transform coference with editions\n",
    "cdf = pd.read_csv('conference_semantic.csv', index_col=False)\n",
    "ppij = pd.read_csv('paper_published_in_journal.csv', index_col=False)\n",
    "ppic = pd.read_csv('paper_presented_in_conference.csv', index_col=False)\n",
    "papers = pd.read_csv('papers_semantic.csv', index_col=False)\n",
    "awp = pd.read_csv('author_writes_papers.csv')\n",
    " \n",
    "published_papers = set(ppij[\":START_ID\"].append(ppij[\":START_ID\"], ignore_index=True))\n",
    "paper_set = set(papers[\":ID\"])\n",
    "\n",
    "unpublished_papers = paper_set.difference(published_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a579df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add conference Data\n",
    "conference_ids = [\"7654260e-79f9-45c5-9663-d72027cf88f3\",\n",
    "\"376732f4-ec63-4b76-bfc8-bbf77119d852\",\n",
    "\"25eaf793-6674-4a6d-864f-6c8ae5428912\",\n",
    "\"1123f25d-add0-4c9c-8f43-c877aab90a0b\",\n",
    "\"b1ee6f13-7776-44aa-a2d5-b79deda2aecb\",\n",
    "\"b83b14d5-4e97-4f22-85e2-0b30dfa042f4\",\n",
    "\"c40f4908-60d1-42b4-8890-380119178833\",\n",
    "\"5afb995f-87ba-455e-bd26-86ae67a10447\",\n",
    "\"c2ff5df6-f2f4-4573-a884-8c53979d4c78\",\n",
    "\"5042fe05-b1f6-41b6-8092-53294b52cbd6\",\n",
    "\"bb718fdd-6d66-4f93-851b-08eeeefb28f5\",\n",
    "\"0efa120a-36c7-45fa-b534-597651ae69d2\",\n",
    "\"019d3f59-a115-42e3-bd7b-474dd4246499\",\n",
    "\"bedd754b-5faf-4eff-8074-3c90be8ac9b0\",\n",
    "\"0256ebd3-4f16-4fd0-91bc-b0e77fcd3c0d\",\n",
    "\"f3dd946e-cb75-4502-b550-9dec04bda7f9\",\n",
    "\"3ff00d27-28c7-4770-a1c7-855a072843fd\",\n",
    "\"4c562775-121a-4c25-9f7a-823f54d0e93e\",\n",
    "\"10ff739d-ef5f-48b7-9454-9cd1c6d2434d\",\n",
    "\"3837ff2b-82e5-4165-8900-b069c31ef3d7\",\n",
    "\"b55b50b1-aae7-47a7-b042-8aecc930073d\",\n",
    "\"c85dfc25-bcef-4719-9997-f41ad334d998\",\n",
    "\"d7907408-25bc-4816-a81d-4e0f2f6482c8\"\n",
    "]\n",
    "\n",
    "journals = [\"c6840156-ee10-4d78-8832-7f8909811576\",\n",
    "\"d60da343-ab92-4310-b3d7-2c0860287a9d\",\n",
    "\"27475f31-a1d2-401b-84ad-9b405c7609a8\",\n",
    "\"961301b0-6f5a-44a6-9216-54b673cded78\",\n",
    "\"bc30f894-9a9c-440e-8420-7bd3c5624384\"]\n",
    "\n",
    "unpublished_papers = list(unpublished_papers)\n",
    "for_journals = unpublished_papers[len(unpublished_papers)//2+1:]\n",
    "for_conferences = unpublished_papers[:len(unpublished_papers)//2+1]\n",
    "\n",
    "\n",
    "paper_presented_in_conference = {\":START_ID\" : [], \":END_ID\": []}\n",
    "paper_published_in_journal = {\":START_ID\" : [], \":END_ID\": [], \"volume:STRING\": [], \"year:INT\": []}\n",
    "\n",
    "### Assign paper to conference\n",
    "index = 0\n",
    "for paper in for_conferences:\n",
    "    paper_presented_in_conference[\":START_ID\"].append(paper)\n",
    "    paper_presented_in_conference[\":END_ID\"].append(conference_ids[index%len(conference_ids)])\n",
    "    index += 1\n",
    "\n",
    "    \n",
    "### Assign paper to journal\n",
    "avail_paper = len(for_journals)\n",
    "while avail_paper > 0:\n",
    "    for journal in journals:\n",
    "        if avail_paper <= 0:\n",
    "            break\n",
    "\n",
    "        year = 2017\n",
    "        volume = 1\n",
    "        \n",
    "        for i in range(5):\n",
    "            if avail_paper <= 0:\n",
    "                break\n",
    "                \n",
    "            paper_published_in_journal[\":START_ID\"].append(for_journals[avail_paper-1])\n",
    "            paper_published_in_journal[\":END_ID\"].append(journal)\n",
    "            paper_published_in_journal[\"volume:STRING\"].append(volume)\n",
    "            paper_published_in_journal[\"year:INT\"].append(year)\n",
    "            \n",
    "            year += 1\n",
    "            volume += 1\n",
    "            avail_paper -= 1\n",
    "\n",
    "\n",
    "### Assign authors to review paper\n",
    "author_writes_papers = {\":START_ID\" : [], \":END_ID\": [], \"corresponding_author:BOOLEAN\": []}\n",
    "authors = [\"144110054\",\n",
    "\"147069795\",\n",
    "\"4376295\",\n",
    "\"2395456\",\n",
    "\"8504175\",\n",
    "\"145073266\"\n",
    "\n",
    "]\n",
    "\n",
    "avail_paper = len(for_conferences)\n",
    "while avail_paper > 0:\n",
    "    for author in authors:\n",
    "        if avail_paper <= 0:\n",
    "            break\n",
    "\n",
    "        \n",
    "        for i in range(5):\n",
    "            if avail_paper <= 0:\n",
    "                break\n",
    "                \n",
    "            author_writes_papers[\":START_ID\"].append(author)\n",
    "            author_writes_papers[\":END_ID\"].append(for_conferences[avail_paper-1])\n",
    "            author_writes_papers[\"corresponding_author:BOOLEAN\"].append(False)\n",
    "            \n",
    "            avail_paper -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a7518e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_425527/234618308.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  awp = awp.append(pd.DataFrame.from_dict(author_writes_papers), ignore_index=True)\n",
      "/tmp/ipykernel_425527/234618308.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ppij = ppij.append(pd.DataFrame.from_dict(paper_published_in_journal), ignore_index=True)\n",
      "/tmp/ipykernel_425527/234618308.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ppic = ppic.append(pd.DataFrame.from_dict(paper_presented_in_conference), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "### Export additional data\n",
    "\n",
    "awp = awp.append(pd.DataFrame.from_dict(author_writes_papers), ignore_index=True)\n",
    "ppij = ppij.append(pd.DataFrame.from_dict(paper_published_in_journal), ignore_index=True)\n",
    "ppic = ppic.append(pd.DataFrame.from_dict(paper_presented_in_conference), ignore_index=True)\n",
    "\n",
    "awp.to_csv(\"author_write_papers_1.csv\", index=False)\n",
    "ppij.to_csv(\"paper_published_in_journal_1.csv\", index=False)\n",
    "ppic.to_csv(\"paper_presented_in_conference_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4da5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
